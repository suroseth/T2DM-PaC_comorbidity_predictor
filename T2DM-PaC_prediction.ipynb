{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8e890dbe",
   "metadata": {},
   "source": [
    "###########################################################################################\n",
    "# To predict T2DM-PaC comorbidity\n",
    "# Input: pre-processed and normalized gene expression data\n",
    "# OUTPUT: Score file with 3 columns, for T2DM prediction, PaC prediction, and comorbidity prediction.  \n",
    "# OUTPT: '1' indicates the presence and '0' indicates the absence of respective disease\n",
    "###########################################################################################\n",
    "# load the expression values of 67 genes features (upload in google colab drive) \n",
    "# upload the model files gnb_pac.sav, xgb_pac.sav, svm_t2d.sav, lr_t2d.sav, (upload in google colab drive)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83de6268",
   "metadata": {},
   "source": [
    "#install required packages \n",
    "pip install pickle # usually not required in google colab\n",
    "pip install pandas # usually not required in google colab\n",
    "pip install numpy # usually not required in google colab\n",
    "pip install repeat # usually not required in google colab\n",
    "pip install os # usually not required in google colab\n",
    "pip install dill\n",
    "pip install scikit-optimize\n",
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f8cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required packages\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "import os\n",
    "import dill\n",
    "import skopt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7445d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to fit into distribution of training set\n",
    "def match_quantiles(counts_sub, old_mu, old_phi, new_mu, new_phi):\n",
    " \n",
    "    new_counts_sub = np.zeros_like(counts_sub, dtype=float)\n",
    "    for a in range(counts_sub.shape[0]):\n",
    "        for b in range(counts_sub.shape[1]):\n",
    "            if counts_sub[a, b] <= 1:\n",
    "                new_counts_sub[a, b] = counts_sub[a, b]\n",
    "            else:\n",
    "                r_old = 1/old_phi[a]  # size parameter (r in negative binomial)\n",
    "                p_old = r_old/(r_old + old_mu[a, b])  # convert mu to probability parameter\n",
    "                \n",
    "                # Calculate CDF (equivalent to pnbinom in R)\n",
    "                tmp_p = stats.nbinom.cdf(counts_sub[a, b]-1, r_old, p_old)\n",
    "                \n",
    "                if abs(tmp_p - 1) < 1e-4:\n",
    "                    new_counts_sub[a, b] = counts_sub[a, b]  # for outlier count\n",
    "                else:\n",
    "                    r_new = 1/new_phi[a]  # new size parameter\n",
    "                    p_new = r_new/(r_new + new_mu[a, b])  # new probability parameter\n",
    "                    \n",
    "                    # Calculate quantile (equivalent to qnbinom in R)\n",
    "                    new_counts_sub[a, b] = 1 + stats.nbinom.ppf(tmp_p, r_new, p_new)\n",
    "    \n",
    "    return new_counts_sub\n",
    "\n",
    "\n",
    "def adding_parameters(new_counts, parameters, batch_number, gene_list):\n",
    "\n",
    "    if not isinstance(parameters, pd.DataFrame):\n",
    "        parameters = pd.DataFrame(parameters)\n",
    "    if not isinstance(new_counts, pd.DataFrame):\n",
    "        new_counts = pd.DataFrame(new_counts)\n",
    "    \n",
    "    # Sort parameters by row names\n",
    "    parameters = parameters.sort_index()\n",
    "    \n",
    "    # Filter new_counts to include only genes in gene_list\n",
    "    new_counts = new_counts.loc[new_counts.index.isin(gene_list)]\n",
    "    \n",
    "    # Sort new_counts by row names\n",
    "    new_counts = new_counts.sort_index()\n",
    "    \n",
    "    # Extract parameters for the specific batch\n",
    "    col1 = f\"old_mu_avg{batch_number}\"\n",
    "    old_mu_avg = parameters.loc[parameters.index.isin(gene_list), col1].values.reshape(-1, 1)\n",
    "    \n",
    "    col2 = f\"old_phi_avg{batch_number}\"\n",
    "    old_phi_avg = parameters.loc[parameters.index.isin(gene_list), col2].values\n",
    "    \n",
    "    col3 = f\"new_mu_avg{batch_number}\"\n",
    "    new_mu_avg = parameters.loc[parameters.index.isin(gene_list), col3].values.reshape(-1, 1)\n",
    "    \n",
    "    col4 = f\"new_phi_avg{batch_number}\"\n",
    "    new_phi_avg = parameters.loc[parameters.index.isin(gene_list), col4].values\n",
    "    \n",
    "    # Initialize result matrix\n",
    "    result_x = np.zeros((new_counts.shape[0], 0))\n",
    "    \n",
    "    # Process each column\n",
    "    for i in range(new_counts.shape[1]):\n",
    "        x = match_quantiles(\n",
    "            counts_sub=new_counts.iloc[:, i].values.reshape(-1, 1),\n",
    "            old_mu=old_mu_avg,\n",
    "            old_phi=old_phi_avg,\n",
    "            new_mu=new_mu_avg,\n",
    "            new_phi=new_phi_avg\n",
    "        )\n",
    "        result_x = np.column_stack((result_x, x))\n",
    "    \n",
    "    # Create DataFrame with proper row and column names\n",
    "    result_df = pd.DataFrame(result_x, index=new_counts.index, columns=new_counts.columns)\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd55fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "\n",
    "t2d_combat_param = pd.read_csv(\"t2d_nor_param.csv\",index_col=0)\n",
    "pac_combat_param = pd.read_csv(\"pac_nor_param.csv\",index_col=0)\n",
    "genes_67_features = pd.read_csv(\"comorbidity_features.csv\")\n",
    "\n",
    "#data loading\n",
    "#os.chdir(\"./T2DM-PaC_comorbidity_predictor-main\")#change working directory\n",
    "input_file_name = \"./pre_processing_example/input_data.csv\" #change file name with your input file\n",
    "input_data = pd.read_csv(input_file_name,index_col=0)\n",
    "\n",
    "#input pac model\n",
    "input_data_pac = adding_parameters(input_data, pac_combat_param, batch_number=8, gene_list=genes_67_features['Genes'])\n",
    "input_data_pac = input_data_pac.transpose()\n",
    "#input_data_pac.columns = input_data_pac.iloc[0,]\n",
    "#input_data_pac.drop([\"genes\"], inplace = True)\n",
    "sample_index = input_data_pac.index\n",
    "input_data_pac_2 =np.array(input_data_pac)\n",
    "\n",
    "#input t2d model\n",
    "input_data_t2d = adding_parameters(input_data, t2d_combat_param, batch_number=7, gene_list=genes_67_features['Genes'])\n",
    "input_data_t2d = input_data_t2d.transpose()\n",
    "#input_data_t2d.columns = input_data_t2d.iloc[0,]\n",
    "#input_data_t2d.drop([\"genes\"], inplace = True)\n",
    "sample_index = input_data_t2d.index\n",
    "input_data_t2d_2 =np.array(input_data_t2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078d0fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surabhi Seth\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:299: UserWarning: Trying to unpickle estimator GaussianNB from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:58:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Surabhi Seth\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:299: UserWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Surabhi Seth\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:299: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "####MODEL LOADING####\n",
    "#load PaC model\n",
    "pac_gnb_model = pickle.load(open('./Models/gnb_pac.sav', 'rb'))\n",
    "pac_xgb_model = pickle.load(open('./Models/xgb_pac.sav', 'rb'))\n",
    "cutoff_threshold_pac = 0.52\n",
    "#load t2D model\n",
    "t2d_svm_model = pickle.load(open('./Models/svm_t2d.sav', 'rb'))\n",
    "t2d_lr_model = pickle.load(open('./Models/lr_t2d.sav', 'rb'))\n",
    "cutoff_threshold_t2d = 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e9ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "####MAKING PREDICTION####\n",
    "#t2d prediction\n",
    "t2d_lr_como = pd.DataFrame(t2d_lr_model.predict_proba(input_data_t2d),columns=[\"0\",\"1\"])\n",
    "t2d_svm_como = pd.DataFrame(t2d_svm_model.predict_proba(input_data_t2d),columns=[\"0\",\"1\"])\n",
    "#pac prediction\n",
    "pac_xgb_como = pd.DataFrame(pac_xgb_model.predict_proba(input_data_pac_2),columns=[\"0\",\"1\"])\n",
    "pac_gnb_como = pd.DataFrame(pac_gnb_model.predict_proba(input_data_pac),columns=[\"0\",\"1\"])\n",
    "\n",
    "####WEIGHTED MODEL COMBINATION####\n",
    "#pac combination\n",
    "w_pac_gnb_co = 0.5161821449336343*pac_gnb_como.iloc[:,1]\n",
    "w_pac_xgb_co = 0.9856469185969381*pac_xgb_como.iloc[:,1]\n",
    "average_predictions_pac = (w_pac_gnb_co + w_pac_xgb_co)/(0.5161821449336343+0.9856469185969381)\n",
    "results_pac_test = (average_predictions_pac >= cutoff_threshold_pac).astype(int)\n",
    "#t2d combination\n",
    "w_t2d_svm_co = 0.8262620868032353*t2d_svm_como.iloc[:,1]\n",
    "w_t2d_lr_co = 0.5484805963516988*t2d_lr_como.iloc[:,1]\n",
    "average_predictions_t2d = (w_t2d_svm_co + w_t2d_lr_co)/(0.8262620868032353+0.5484805963516988)\n",
    "results_t2d_test = (average_predictions_t2d >= cutoff_threshold_t2d).astype(int)\n",
    "\n",
    "#comorbidity voting\n",
    "average_prediction = (results_t2d_test + results_pac_test)/2\n",
    "results_como = (average_prediction == 1).astype(int)\n",
    "\n",
    "df_c = pd.concat([results_pac_test,results_t2d_test,results_como], axis=1)\n",
    "df_c.columns = [\"PaC_prediction\",\"T2D_prediction\",\"comorbidity_prediction\"]\n",
    "df_c.index = sample_index\n",
    "df_c.to_csv(\"output_data.csv\")#,index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb8e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
